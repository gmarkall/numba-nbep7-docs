

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>3.16. External Memory Management (EMM) Plugin interface &mdash; Numba 0.49.0dev0+671.g712bb69ad documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/numba-blue-icon-rgb.svg"/>
  
  
  
    <link rel="canonical" href="http://numba.pydata.org/numba-doc/latest/index.htmlcuda/external-memory.html"/>
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3.17. CUDA Frequently Asked Questions" href="faq.html" />
    <link rel="prev" title="3.15. CUDA Array Interface (Version 2)" href="cuda_array_interface.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #00A3E0" >
          

          
            <a href="../index.html" class="icon icon-home"> Numba
          

          
            
            <img src="../_static/numba-white-icon-rgb.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.49
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../user/index.html">1. User Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">2. Reference Manual</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">3. Numba for CUDA GPUs</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="overview.html">3.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="kernels.html">3.2. Writing CUDA Kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="memory.html">3.3. Memory management</a></li>
<li class="toctree-l2"><a class="reference internal" href="device-functions.html">3.4. Writing Device Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="cudapysupported.html">3.5. Supported Python features in CUDA Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="intrinsics.html">3.6. Supported Atomic Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="random.html">3.7. Random Number Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="device-management.html">3.8. Device management</a></li>
<li class="toctree-l2"><a class="reference internal" href="device-management.html#the-device-list">3.9. The Device List</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples.html">3.10. Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="simulator.html">3.11. Debugging CUDA Python with the the CUDA Simulator</a></li>
<li class="toctree-l2"><a class="reference internal" href="reduction.html">3.12. GPU Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="ufunc.html">3.13. CUDA Ufuncs and Generalized Ufuncs</a></li>
<li class="toctree-l2"><a class="reference internal" href="ipc.html">3.14. Sharing CUDA Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="cuda_array_interface.html">3.15. CUDA Array Interface (Version 2)</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">3.16. External Memory Management (EMM) Plugin interface</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview-of-external-memory-management">3.16.1. Overview of External Memory Management</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#effects-on-deallocation-strategies">3.16.1.1. Effects on Deallocation Strategies</a></li>
<li class="toctree-l4"><a class="reference internal" href="#management-of-other-objects">3.16.1.2. Management of other objects</a></li>
<li class="toctree-l4"><a class="reference internal" href="#asynchronous-allocation-and-deallocation">3.16.1.3. Asynchronous allocation and deallocation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#implementing-an-emm-plugin">3.16.2. Implementing an EMM Plugin</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#the-host-only-cuda-memory-manager">3.16.2.1. The Host-Only CUDA Memory Manager</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#classes-and-structures-of-returned-objects">3.16.3. Classes and structures of returned objects</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#memory-pointers">3.16.3.1. Memory Pointers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#memory-info">3.16.3.2. Memory Info</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ipc">3.16.3.3. IPC</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#setting-the-emm-plugin">3.16.4. Setting the EMM Plugin</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#environment-variable">3.16.4.1. Environment variable</a></li>
<li class="toctree-l4"><a class="reference internal" href="#function">3.16.4.2. Function</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="faq.html">3.17. CUDA Frequently Asked Questions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cuda-reference/index.html">4. CUDA Python Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../roc/index.html">5. Numba for AMD ROC GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extending/index.html">6. Extending Numba</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/index.html">7. Developer Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../proposals/index.html">8. Numba Enhancement Proposals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">9. Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release-notes.html">10. Release Notes</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Numba</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">3. Numba for CUDA GPUs</a> &raquo;</li>
        
      <li>3.16. External Memory Management (EMM) Plugin interface</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/cuda/external-memory.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="external-memory-management-emm-plugin-interface">
<span id="cuda-emm-plugin"></span><h1>3.16. External Memory Management (EMM) Plugin interface<a class="headerlink" href="#external-memory-management-emm-plugin-interface" title="Permalink to this headline">Â¶</a></h1>
<p>The <a class="reference internal" href="cuda_array_interface.html#cuda-array-interface"><span class="std std-ref">CUDA Array Interface</span></a> enables sharing of data
between different Python libraries that access CUDA devices. However, each
library manages its own memory distinctly from the others. For example:</p>
<ul class="simple">
<li><p>By default, Numba allocates memory on CUDA devices by interacting with the
CUDA driver API to call functions such as <code class="docutils literal notranslate"><span class="pre">cuMemAlloc</span></code> and <code class="docutils literal notranslate"><span class="pre">cuMemFree</span></code>,
which is suitable for many use cases.</p></li>
<li><p>The RAPIDS libraries (cuDF, cuML, etc.) use the <a class="reference external" href="https://github.com/rapidsai/rmm">RAPIDS Memory Manager (RMM)</a> for allocating device memory.</p></li>
<li><p><a class="reference external" href="https://cupy.chainer.org/">CuPy</a> includes a <a class="reference external" href="https://docs-cupy.chainer.org/en/stable/reference/memory.html">memory pool implementation</a> for both
device and pinned memory.</p></li>
</ul>
<p>When multiple CUDA-aware libraries are used together, it may be preferable for
Numba to defer to another library for memory management. The EMM Plugin
interface facilitates this, by enabling Numba to use another CUDA-aware library
for all allocations and deallocations.</p>
<p>An EMM Plugin is used to facilitate the use of an external library for memory
management. An EMM Plugin can be a part of an external library, or could be
implemented as a separate library.</p>
<div class="section" id="overview-of-external-memory-management">
<h2>3.16.1. Overview of External Memory Management<a class="headerlink" href="#overview-of-external-memory-management" title="Permalink to this headline">Â¶</a></h2>
<p>When an EMM Plugin is in use (see <a class="reference internal" href="#setting-emm-plugin"><span class="std std-ref">Setting the EMM Plugin</span></a>), Numba will make
does allocation and deallocation through the Plugin. It will never directly call
functions such as <code class="docutils literal notranslate"><span class="pre">cuMemAlloc</span></code>, <code class="docutils literal notranslate"><span class="pre">cuMemFree</span></code>, etc.</p>
<p>EMM Plugins always take responsibility for the management of device memory.
However, not all CUDA-aware libraries also support managing host memory, so a
facility for Numba to continue the management of host memory whilst ceding
control of device memory to the EMM is provided (see
<a class="reference internal" href="#host-only-cuda-memory-manager"><span class="std std-ref">The Host-Only CUDA Memory Manager</span></a>).</p>
<div class="section" id="effects-on-deallocation-strategies">
<h3>3.16.1.1. Effects on Deallocation Strategies<a class="headerlink" href="#effects-on-deallocation-strategies" title="Permalink to this headline">Â¶</a></h3>
<p>Numbaâs internal <a class="reference internal" href="memory.html#deallocation-behavior"><span class="std std-ref">Deallocation Behavior</span></a> is designed to increase efficiency
by deferring deallocations until a significant quantity are pending. It also
provides a mechanism for preventing deallocations entirely during critical
sections, using the <a class="reference internal" href="memory.html#numba.cuda.defer_cleanup" title="numba.cuda.defer_cleanup"><code class="xref py py-func docutils literal notranslate"><span class="pre">defer_cleanup()</span></code></a> context manager.</p>
<p>When an EMM Plugin is in use, the deallocation strategy is implemented by the
EMM, and Numbaâs internal deallocation mechanism is not used. The EMM
Plugin could implement:</p>
<ul class="simple">
<li><p>A similar strategy to the Numba deallocation behaviour, or</p></li>
<li><p>Something more appropriate to the plugin - for example, deallocated memory
might immediately be returned to a memory pool.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">defer_cleanup</span></code> context manager may behave differently with an EMM Plugin
- an EMM Plugin should be accompanied by documentation of the behaviour of the
<code class="docutils literal notranslate"><span class="pre">defer_cleanup</span></code> context manager when it is in use. For example, a pool
allocator could always immediately return memory to a pool even when the
context manager is in use, but could choose not to free empty pools until
<code class="docutils literal notranslate"><span class="pre">defer_cleanup</span></code> is not in use.</p>
</div>
<div class="section" id="management-of-other-objects">
<h3>3.16.1.2. Management of other objects<a class="headerlink" href="#management-of-other-objects" title="Permalink to this headline">Â¶</a></h3>
<p>In addition to memory, Numba manages the allocation and deallocation of
<a class="reference internal" href="../cuda-reference/host.html#events"><span class="std std-ref">events</span></a>, <a class="reference internal" href="../cuda-reference/host.html#streams"><span class="std std-ref">streams</span></a>, and modules (modules are a
compiled objects, which is generated for CUDA kernels). The management of
events, streams, and modules is unchanged by the use of an EMM Plugin.</p>
</div>
<div class="section" id="asynchronous-allocation-and-deallocation">
<h3>3.16.1.3. Asynchronous allocation and deallocation<a class="headerlink" href="#asynchronous-allocation-and-deallocation" title="Permalink to this headline">Â¶</a></h3>
<p>The present EMM Plugin interface does not provide support for asynchronous
allocation and deallocation. This may be added to a future version of the
interface.</p>
</div>
</div>
<div class="section" id="implementing-an-emm-plugin">
<h2>3.16.2. Implementing an EMM Plugin<a class="headerlink" href="#implementing-an-emm-plugin" title="Permalink to this headline">Â¶</a></h2>
<p>An EMM Plugin is implemented by deriving from
<a class="reference internal" href="#numba.cuda.BaseCUDAMemoryManager" title="numba.cuda.BaseCUDAMemoryManager"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseCUDAMemoryManager</span></code></a>. A summary of considerations for the
implementation follows:</p>
<ul class="simple">
<li><p>Numba instantiates one instance of the EMM Plugin class per context. The
context that owns an EMM Plugin object is accessible through <code class="docutils literal notranslate"><span class="pre">self.context</span></code>,
if required.</p></li>
<li><p>The EMM Plugin is transparent to any code that uses Numba - all its methods
are invoked by Numba, and never need to be called by code that uses Numba.</p></li>
<li><p>The allocation methods <code class="docutils literal notranslate"><span class="pre">memalloc</span></code>, <code class="docutils literal notranslate"><span class="pre">memhostalloc</span></code>, and <code class="docutils literal notranslate"><span class="pre">mempin</span></code>, should
use the underlying library to allocate and/or pin device or host memory, and
construct an instance of a <a class="reference internal" href="#memory-pointers"><span class="std std-ref">memory pointer</span></a>
representing the memory to return back to Numba. These methods are always
called when the current CUDA context is the context that owns the EMM Plugin
instance.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">initialize</span></code> method is called by Numba prior to the first use of the EMM
Plugin object for a context. This method should do anything required to
prepare the underlying library for allocations in the current context. This
method may be called multiple times, and must not invalidate previous state
when it is called.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">reset</span></code> method is called when all allocations in the context are to be
cleaned up. It may be called even prior to <code class="docutils literal notranslate"><span class="pre">initialize</span></code>, and an EMM Plugin
implementation needs to guard against this.</p></li>
<li><p>To support inter-GPU communication, the <code class="docutils literal notranslate"><span class="pre">get_ipc_handle</span></code> method should
provide an <a class="reference internal" href="#numba.cuda.IpcHandle" title="numba.cuda.IpcHandle"><code class="xref py py-class docutils literal notranslate"><span class="pre">IpcHandle</span></code></a> for a given
<a class="reference internal" href="#numba.cuda.MemoryPointer" title="numba.cuda.MemoryPointer"><code class="xref py py-class docutils literal notranslate"><span class="pre">MemoryPointer</span></code></a> instance. This method is part of the EMM
interface (rather than being handled within Numba) because the base address of
the allocation is only known by the underlying library. Closing an IPC handle
is handled internally within Numba.</p></li>
<li><p>It is optional provide memory info from the <code class="docutils literal notranslate"><span class="pre">get_memory_info</span></code> method, which
provides a count of the total and free memory on the device for the context.
It is preferrable to implement the method, but this may not be practical for
all allocators. If memory info is not provided, this method should raise a
<a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">RuntimeError</span></code></a>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">defer_cleanup</span></code> method should return a context manager that ensures that
expensive cleanup operations are avoided whilst it is active. The nuances of
this will vary between plugins, so the plugin documentation should include an
explanation of how deferring cleanup affects deallocations, and performance in
general.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">interface_version</span></code> property is used to ensure that the plugin version
matches the interface provided by the version of Numba. At present, this
should always be 1.</p></li>
</ul>
<p>Full documentation for the base class follows:</p>
<dl class="class">
<dt id="numba.cuda.BaseCUDAMemoryManager">
<em class="property">class </em><code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">BaseCUDAMemoryManager</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.BaseCUDAMemoryManager" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Abstract base class for External Memory Management (EMM) Plugins.</p>
<dl class="method">
<dt id="numba.cuda.BaseCUDAMemoryManager.memalloc">
<em class="property">abstract </em><code class="sig-name descname">memalloc</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">size</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.BaseCUDAMemoryManager.memalloc" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Allocate on-device memory in the current context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) â Size of allocation in bytes</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A memory pointer instance that owns the allocated memory</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#numba.cuda.MemoryPointer" title="numba.cuda.MemoryPointer"><code class="xref py py-class docutils literal notranslate"><span class="pre">MemoryPointer</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.BaseCUDAMemoryManager.memhostalloc">
<em class="property">abstract </em><code class="sig-name descname">memhostalloc</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">size</em>, <em class="sig-param">mapped</em>, <em class="sig-param">portable</em>, <em class="sig-param">wc</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.BaseCUDAMemoryManager.memhostalloc" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Allocate pinned host memory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) â Size of the allocation in bytes</p></li>
<li><p><strong>mapped</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) â Whether the allocated memory should be mapped into the CUDA
address space.</p></li>
<li><p><strong>portable</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) â Whether the memory will be considered pinned by all
contexts, and not just the calling context.</p></li>
<li><p><strong>wc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) â Whether to allocate the memory as write-combined.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A memory pointer instance that owns the allocated memory. The
return type depends on whether the region was mapped into
device memory.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#numba.cuda.MappedMemory" title="numba.cuda.MappedMemory"><code class="xref py py-class docutils literal notranslate"><span class="pre">MappedMemory</span></code></a> or <a class="reference internal" href="#numba.cuda.PinnedMemory" title="numba.cuda.PinnedMemory"><code class="xref py py-class docutils literal notranslate"><span class="pre">PinnedMemory</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.BaseCUDAMemoryManager.mempin">
<em class="property">abstract </em><code class="sig-name descname">mempin</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">owner</em>, <em class="sig-param">pointer</em>, <em class="sig-param">size</em>, <em class="sig-param">mapped</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.BaseCUDAMemoryManager.mempin" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Pin a region of host memory that is already allocated.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>owner</strong> â The object that owns the memory.</p></li>
<li><p><strong>pointer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) â The pointer to the beginning of the region to pin.</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) â The size of the region in bytes.</p></li>
<li><p><strong>mapped</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) â Whether the region should also be mapped into device memory.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A memory pointer instance that refers to the allocated
memory.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#numba.cuda.MappedMemory" title="numba.cuda.MappedMemory"><code class="xref py py-class docutils literal notranslate"><span class="pre">MappedMemory</span></code></a> or <a class="reference internal" href="#numba.cuda.PinnedMemory" title="numba.cuda.PinnedMemory"><code class="xref py py-class docutils literal notranslate"><span class="pre">PinnedMemory</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.BaseCUDAMemoryManager.initialize">
<em class="property">abstract </em><code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.BaseCUDAMemoryManager.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Perform any initialization required for the EMM plugin instance to be
ready to use.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.BaseCUDAMemoryManager.get_ipc_handle">
<em class="property">abstract </em><code class="sig-name descname">get_ipc_handle</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">memory</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.BaseCUDAMemoryManager.get_ipc_handle" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return an IPC handle from a GPU allocation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>memory</strong> (<a class="reference internal" href="#numba.cuda.MemoryPointer" title="numba.cuda.MemoryPointer"><code class="xref py py-class docutils literal notranslate"><span class="pre">MemoryPointer</span></code></a>) â Memory for which the IPC handle should be created.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>IPC handle for the allocation</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#numba.cuda.IpcHandle" title="numba.cuda.IpcHandle"><code class="xref py py-class docutils literal notranslate"><span class="pre">IpcHandle</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.BaseCUDAMemoryManager.get_memory_info">
<em class="property">abstract </em><code class="sig-name descname">get_memory_info</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.BaseCUDAMemoryManager.get_memory_info" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns <code class="docutils literal notranslate"><span class="pre">(free,</span> <span class="pre">total)</span></code> memory in bytes in the context. May raise
<a class="reference external" href="https://docs.python.org/3/library/exceptions.html#NotImplementedError" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">NotImplementedError</span></code></a>, if returning such information is not
practical (e.g. for a pool allocator).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Memory info</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#numba.cuda.MemoryInfo" title="numba.cuda.MemoryInfo"><code class="xref py py-class docutils literal notranslate"><span class="pre">MemoryInfo</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.BaseCUDAMemoryManager.reset">
<em class="property">abstract </em><code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.BaseCUDAMemoryManager.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Clear up all memory allocated in this context.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.BaseCUDAMemoryManager.defer_cleanup">
<em class="property">abstract </em><code class="sig-name descname">defer_cleanup</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.BaseCUDAMemoryManager.defer_cleanup" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a context manager that ensures the implementation of deferred
cleanup whilst it is active.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Context manager</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.BaseCUDAMemoryManager.interface_version">
<em class="property">abstract property </em><code class="sig-name descname">interface_version</code><a class="headerlink" href="#numba.cuda.BaseCUDAMemoryManager.interface_version" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns an integer specifying the version of the EMM Plugin interface
supported by the plugin implementation. Should always return 1 for
implementations described in this proposal.</p>
</dd></dl>

</dd></dl>

<div class="section" id="the-host-only-cuda-memory-manager">
<span id="host-only-cuda-memory-manager"></span><h3>3.16.2.1. The Host-Only CUDA Memory Manager<a class="headerlink" href="#the-host-only-cuda-memory-manager" title="Permalink to this headline">Â¶</a></h3>
<p>Some external memory managers will support management of on-device memory but
not host memory. For implementing EMM Plugins using one of these memory
managers, a partial implementation of a plugin that implements host-side
allocation and pinning is provided. To use it, derive from
<a class="reference internal" href="#numba.cuda.HostOnlyCUDAMemoryManager" title="numba.cuda.HostOnlyCUDAMemoryManager"><code class="xref py py-class docutils literal notranslate"><span class="pre">HostOnlyCUDAMemoryManager</span></code></a> instead of
<a class="reference internal" href="#numba.cuda.BaseCUDAMemoryManager" title="numba.cuda.BaseCUDAMemoryManager"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseCUDAMemoryManager</span></code></a>. Guidelines for using this class
are:</p>
<ul class="simple">
<li><p>The host-only memory manager implements <code class="docutils literal notranslate"><span class="pre">memhostalloc</span></code> and <code class="docutils literal notranslate"><span class="pre">mempin</span></code> - the
EMM Plugin should still implement <code class="docutils literal notranslate"><span class="pre">memalloc</span></code>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">reset</span></code> is overridden, it must also call <code class="docutils literal notranslate"><span class="pre">super().reset()</span></code> to allow the
host allocations to be cleaned up.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">defer_cleanup</span></code> is overridden, it must hold an active context manager
from <code class="docutils literal notranslate"><span class="pre">super().defer_cleanup()</span></code> to ensure that host-side cleanup is also
deferred.</p></li>
</ul>
<p>Documentation for the methods of <a class="reference internal" href="#numba.cuda.HostOnlyCUDAMemoryManager" title="numba.cuda.HostOnlyCUDAMemoryManager"><code class="xref py py-class docutils literal notranslate"><span class="pre">HostOnlyCUDAMemoryManager</span></code></a>
follows:</p>
<dl class="class">
<dt id="numba.cuda.HostOnlyCUDAMemoryManager">
<em class="property">class </em><code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">HostOnlyCUDAMemoryManager</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.HostOnlyCUDAMemoryManager" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Base class for External Memory Management (EMM) Plugins that only
implement on-device allocation. A subclass need not implement the
<code class="docutils literal notranslate"><span class="pre">memhostalloc</span></code> and <code class="docutils literal notranslate"><span class="pre">mempin</span></code> methods.</p>
<p>This class also implements <code class="docutils literal notranslate"><span class="pre">reset</span></code> and <code class="docutils literal notranslate"><span class="pre">defer_cleanup</span></code> (see
<a class="reference internal" href="#numba.cuda.BaseCUDAMemoryManager" title="numba.cuda.BaseCUDAMemoryManager"><code class="xref py py-class docutils literal notranslate"><span class="pre">numba.cuda.BaseCUDAMemoryManager</span></code></a>) for its own internal state
management. If an EMM Plugin based on this class also implements these
methods, then its implementations of these must also call the method from
<code class="docutils literal notranslate"><span class="pre">super()</span></code> to give <code class="docutils literal notranslate"><span class="pre">HostOnlyCUDAMemoryManager</span></code> an opportunity  to do the
necessary work for the host allocations it is managing.</p>
<p>This class does not implement <code class="docutils literal notranslate"><span class="pre">interface_version</span></code>, as it will always be
consistent with the version of Numba in which it is implemented. An EMM
Plugin subclassing this class should implement <code class="docutils literal notranslate"><span class="pre">interface_version</span></code>
instead.</p>
<dl class="method">
<dt id="numba.cuda.HostOnlyCUDAMemoryManager.memhostalloc">
<code class="sig-name descname">memhostalloc</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">size</em>, <em class="sig-param">mapped=False</em>, <em class="sig-param">portable=False</em>, <em class="sig-param">wc=False</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.HostOnlyCUDAMemoryManager.memhostalloc" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Implements the allocation of pinned host memory.</p>
<p>It is recommended that this method is not overridden by EMM Plugin
implementations - instead, use the <a class="reference internal" href="#numba.cuda.BaseCUDAMemoryManager" title="numba.cuda.BaseCUDAMemoryManager"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseCUDAMemoryManager</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.HostOnlyCUDAMemoryManager.mempin">
<code class="sig-name descname">mempin</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">owner</em>, <em class="sig-param">pointer</em>, <em class="sig-param">size</em>, <em class="sig-param">mapped=False</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.HostOnlyCUDAMemoryManager.mempin" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Implements the pinning of host memory.</p>
<p>It is recommended that this method is not overridden by EMM Plugin
implementations - instead, use the <a class="reference internal" href="#numba.cuda.BaseCUDAMemoryManager" title="numba.cuda.BaseCUDAMemoryManager"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseCUDAMemoryManager</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.HostOnlyCUDAMemoryManager.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.HostOnlyCUDAMemoryManager.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Clears up all host memory (mapped and/or pinned) in the current
context.</p>
<p>EMM Plugins that override this method must call <code class="docutils literal notranslate"><span class="pre">super().reset()</span></code> to
ensure that host allocations are also cleaned up.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.HostOnlyCUDAMemoryManager.defer_cleanup">
<code class="sig-name descname">defer_cleanup</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.HostOnlyCUDAMemoryManager.defer_cleanup" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Disables cleanup of mapped or pinned host memory in the current
context.</p>
<p>EMM Plugins that override this method must obtain the context manager
from this method before yielding to ensure that cleanup of host
allocations is also deferred.</p>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="classes-and-structures-of-returned-objects">
<h2>3.16.3. Classes and structures of returned objects<a class="headerlink" href="#classes-and-structures-of-returned-objects" title="Permalink to this headline">Â¶</a></h2>
<p>This section provides an overview of the classes and structures that need to be
constructed by an EMM Plugin.</p>
<div class="section" id="memory-pointers">
<span id="id1"></span><h3>3.16.3.1. Memory Pointers<a class="headerlink" href="#memory-pointers" title="Permalink to this headline">Â¶</a></h3>
<p>EMM Plugins should construct memory pointer instances that represent their
allocations, for return to Numba. The appopriate memory pointer class to use in
each method is:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#numba.cuda.MemoryPointer" title="numba.cuda.MemoryPointer"><code class="xref py py-class docutils literal notranslate"><span class="pre">MemoryPointer</span></code></a>: returned from <code class="docutils literal notranslate"><span class="pre">memalloc</span></code></p></li>
<li><p><a class="reference internal" href="#numba.cuda.MappedMemory" title="numba.cuda.MappedMemory"><code class="xref py py-class docutils literal notranslate"><span class="pre">MappedMemory</span></code></a>: returned from <code class="docutils literal notranslate"><span class="pre">memhostalloc</span></code> or
<code class="docutils literal notranslate"><span class="pre">mempin</span></code> when the host memory is mapped into the device memory space.</p></li>
<li><p><a class="reference internal" href="#numba.cuda.PinnedMemory" title="numba.cuda.PinnedMemory"><code class="xref py py-class docutils literal notranslate"><span class="pre">PinnedMemory</span></code></a>: return from <code class="docutils literal notranslate"><span class="pre">memhostalloc</span></code> or <code class="docutils literal notranslate"><span class="pre">mempin</span></code>
when the host memory is not mapped into the device memory space.</p></li>
</ul>
<p>Memory pointers can take a finalizer, which is a function that is called when
the buffer is no longer needed. Usually the finalizer will make a call to the
memory management library (either internal to Numba, or external if allocated
by an EMM Plugin) to inform it that the memory is no longer required, and that
it could potentially be freed and/or unpinned. The memory manager may choose to
defer actually cleaning up the memory to any later time after the finalizer
runs - it is not required to free the buffer immediately.</p>
<p>Documentation for the memory pointer classes follows.</p>
<dl class="class">
<dt id="numba.cuda.MemoryPointer">
<em class="property">class </em><code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">MemoryPointer</code><span class="sig-paren">(</span><em class="sig-param">context</em>, <em class="sig-param">pointer</em>, <em class="sig-param">size</em>, <em class="sig-param">owner=None</em>, <em class="sig-param">finalizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.MemoryPointer" title="Permalink to this definition">Â¶</a></dt>
<dd><p>A memory pointer that owns a buffer, with an optional finalizer. Memory
pointers provide reference counting, and instances are initialized with a
reference count of 1.</p>
<p>The base <code class="docutils literal notranslate"><span class="pre">MemoryPointer</span></code> class does not use the
reference count for managing the buffer lifetime. Instead, the buffer
lifetime is tied to the memory pointer instanceâs lifetime:</p>
<ul class="simple">
<li><p>When the instance is deleted, the finalizer will be called.</p></li>
<li><p>When the reference count drops to 0, no action is taken.</p></li>
</ul>
<p>Subclasses of <code class="docutils literal notranslate"><span class="pre">MemoryPointer</span></code> may modify these semantics, for example to
tie the buffer lifetime to the reference count, so that the buffer is freed
when there are no more references.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>context</strong> (<a class="reference internal" href="../cuda-reference/host.html#numba.cuda.cudadrv.driver.Context" title="numba.cuda.cudadrv.driver.Context"><em>Context</em></a>) â The context in which the pointer was allocated.</p></li>
<li><p><strong>pointer</strong> (<a class="reference external" href="https://docs.python.org/3/library/ctypes.html#ctypes.c_void_p" title="(in Python v3.8)"><em>ctypes.c_void_p</em></a>) â The address of the buffer.</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) â The size of the allocation in bytes.</p></li>
<li><p><strong>owner</strong> (<em>NoneType</em>) â The owner is sometimes set by the internals of this class, or used for
Numbaâs internal memory management. It should not be provided
by an external user of the <code class="docutils literal notranslate"><span class="pre">MemoryPointer</span></code> class (e.g. from
within an EMM Plugin); the default of <cite>None</cite> should always
suffice.</p></li>
<li><p><strong>finalizer</strong> (<em>function</em>) â A function that is called when the buffer is to be freed.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<p>The <code class="docutils literal notranslate"><span class="pre">AutoFreePointer</span></code> class need not be used directly, but is documented here
as it is subclassed by <a class="reference internal" href="#numba.cuda.MappedMemory" title="numba.cuda.MappedMemory"><code class="xref py py-class docutils literal notranslate"><span class="pre">numba.cuda.MappedMemory</span></code></a>:</p>
<dl class="class">
<dt id="numba.cuda.cudadrv.driver.AutoFreePointer">
<em class="property">class </em><code class="sig-prename descclassname">numba.cuda.cudadrv.driver.</code><code class="sig-name descname">AutoFreePointer</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.AutoFreePointer" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Modifies the ownership semantic of the MemoryPointer so that the
instance lifetime is directly tied to the number of references.</p>
<p>When the reference count reaches zero, the finalizer is invoked.</p>
<p>Constructor arguments are the same as for <code class="xref py py-class docutils literal notranslate"><span class="pre">MemoryPointer</span></code>.</p>
</dd></dl>

<dl class="class">
<dt id="numba.cuda.MappedMemory">
<em class="property">class </em><code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">MappedMemory</code><span class="sig-paren">(</span><em class="sig-param">context</em>, <em class="sig-param">pointer</em>, <em class="sig-param">size</em>, <em class="sig-param">owner=None</em>, <em class="sig-param">finalizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.MappedMemory" title="Permalink to this definition">Â¶</a></dt>
<dd><p>A memory pointer that owns a buffer on the host that is mapped into
device memory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>context</strong> (<a class="reference internal" href="../cuda-reference/host.html#numba.cuda.cudadrv.driver.Context" title="numba.cuda.cudadrv.driver.Context"><em>Context</em></a>) â The context in which the pointer was mapped.</p></li>
<li><p><strong>pointer</strong> (<a class="reference external" href="https://docs.python.org/3/library/ctypes.html#ctypes.c_void_p" title="(in Python v3.8)"><em>ctypes.c_void_p</em></a>) â The address of the buffer.</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) â The size of the buffer in bytes.</p></li>
<li><p><strong>owner</strong> (<em>NoneType</em>) â The owner is sometimes set by the internals of this class, or used for
Numbaâs internal memory management. It should not be provided
by an external user of the <code class="docutils literal notranslate"><span class="pre">MappedMemory</span></code> class (e.g. from
within an EMM Plugin); the default of <cite>None</cite> should always
suffice.</p></li>
<li><p><strong>finalizer</strong> (<em>function</em>) â A function that is called when the buffer is to be freed.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="numba.cuda.PinnedMemory">
<em class="property">class </em><code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">PinnedMemory</code><span class="sig-paren">(</span><em class="sig-param">context</em>, <em class="sig-param">pointer</em>, <em class="sig-param">size</em>, <em class="sig-param">owner=None</em>, <em class="sig-param">finalizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.PinnedMemory" title="Permalink to this definition">Â¶</a></dt>
<dd><p>A pointer to a pinned buffer on the host.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>context</strong> (<a class="reference internal" href="../cuda-reference/host.html#numba.cuda.cudadrv.driver.Context" title="numba.cuda.cudadrv.driver.Context"><em>Context</em></a>) â The context in which the pointer was mapped.</p></li>
<li><p><strong>owner</strong> â The object owning the memory. For EMM plugin implementation,
this ca</p></li>
<li><p><strong>pointer</strong> (<a class="reference external" href="https://docs.python.org/3/library/ctypes.html#ctypes.c_void_p" title="(in Python v3.8)"><em>ctypes.c_void_p</em></a>) â The address of the buffer.</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) â The size of the buffer in bytes.</p></li>
<li><p><strong>owner</strong> â An object owning the buffer that has been pinned. For EMM
plugin implementation, the default of <code class="docutils literal notranslate"><span class="pre">None</span></code> suffices for
memory allocated in <code class="docutils literal notranslate"><span class="pre">memhostalloc</span></code> - for <code class="docutils literal notranslate"><span class="pre">mempin</span></code>, it
should be the owner passed in to the <code class="docutils literal notranslate"><span class="pre">mempin</span></code> method.</p></li>
<li><p><strong>finalizer</strong> (<em>function</em>) â A function that is called when the buffer is to be freed.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="memory-info">
<h3>3.16.3.2. Memory Info<a class="headerlink" href="#memory-info" title="Permalink to this headline">Â¶</a></h3>
<p>If an implementation of
<a class="reference internal" href="#numba.cuda.BaseCUDAMemoryManager.get_memory_info" title="numba.cuda.BaseCUDAMemoryManager.get_memory_info"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_memory_info()</span></code></a> is to provide a
result, then it should return an instance of the <code class="docutils literal notranslate"><span class="pre">MemoryInfo</span></code> named tuple:</p>
<dl class="class">
<dt id="numba.cuda.MemoryInfo">
<em class="property">class </em><code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">MemoryInfo</code><span class="sig-paren">(</span><em class="sig-param">free</em>, <em class="sig-param">total</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.MemoryInfo" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Free and total memory for a device.</p>
<dl class="attribute">
<dt id="numba.cuda.MemoryInfo.free">
<code class="sig-name descname">free</code><a class="headerlink" href="#numba.cuda.MemoryInfo.free" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Free device memory in bytes.</p>
</dd></dl>

<dl class="attribute">
<dt id="numba.cuda.MemoryInfo.total">
<code class="sig-name descname">total</code><a class="headerlink" href="#numba.cuda.MemoryInfo.total" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Total device memory in bytes.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="ipc">
<h3>3.16.3.3. IPC<a class="headerlink" href="#ipc" title="Permalink to this headline">Â¶</a></h3>
<p>An instance of <code class="docutils literal notranslate"><span class="pre">IpcHandle</span></code> is required to be returned from an implementation
of <a class="reference internal" href="#numba.cuda.BaseCUDAMemoryManager.get_ipc_handle" title="numba.cuda.BaseCUDAMemoryManager.get_ipc_handle"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_ipc_handle()</span></code></a>:</p>
<dl class="class">
<dt id="numba.cuda.IpcHandle">
<em class="property">class </em><code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">IpcHandle</code><span class="sig-paren">(</span><em class="sig-param">base</em>, <em class="sig-param">handle</em>, <em class="sig-param">size</em>, <em class="sig-param">source_info=None</em>, <em class="sig-param">offset=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.IpcHandle" title="Permalink to this definition">Â¶</a></dt>
<dd><p>CUDA IPC handle. Serialization of the CUDA IPC handle object is implemented
here.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base</strong> (<a class="reference internal" href="#numba.cuda.MemoryPointer" title="numba.cuda.MemoryPointer"><em>MemoryPointer</em></a>) â A reference to the original allocation to keep it alive</p></li>
<li><p><strong>handle</strong> â The CUDA IPC handle, as a ctypes array of bytes.</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) â Size of the original allocation</p></li>
<li><p><strong>source_info</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) â The identity of the device on which the IPC handle was
opened.</p></li>
<li><p><strong>offset</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) â The offset into the underlying allocation of the memory
referred to by this IPC handle.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<p>Guidance for constructing an IPC handle in the context of implementing an EMM
Plugin:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">memory</span></code> parameter to <code class="docutils literal notranslate"><span class="pre">get_ipc_handle</span></code> can be passed as the <code class="docutils literal notranslate"><span class="pre">base</span></code>
parameter.</p></li>
<li><p>A suitable type for the <code class="docutils literal notranslate"><span class="pre">handle</span></code> can be constructed as <code class="docutils literal notranslate"><span class="pre">ctypes.c_byte</span> <span class="pre">*</span>
<span class="pre">64</span></code>. The data for <code class="docutils literal notranslate"><span class="pre">handle</span></code> must be populated using a method for obtaining a
CUDA IPC handle appropriate to the underlying library.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">size</span></code> should match the size of the original allocation, which can be
obtained with <code class="docutils literal notranslate"><span class="pre">memory.size</span></code> in <code class="docutils literal notranslate"><span class="pre">get_ipc_handle</span></code>.</p></li>
<li><p>An appropriate value for <code class="docutils literal notranslate"><span class="pre">source_info</span></code> can be created by calling
<code class="docutils literal notranslate"><span class="pre">self.context.device.get_device_identity()</span></code>.</p></li>
<li><p>If the underlying memory does not point to the base of an allocation returned
by the CUDA driver or runtime API (e.g. if a pool allocator is in use) then
the <code class="docutils literal notranslate"><span class="pre">offset</span></code> from the base must be provided.</p></li>
</ul>
</div>
</div>
<div class="section" id="setting-the-emm-plugin">
<span id="setting-emm-plugin"></span><h2>3.16.4. Setting the EMM Plugin<a class="headerlink" href="#setting-the-emm-plugin" title="Permalink to this headline">Â¶</a></h2>
<p>By default, Numba uses its internal memory management - if an EMM Plugin is to
be used, it must be configured. There are two mechanisms for configuring the use
of an EMM Plugin: an environment variable, and a function.</p>
<div class="section" id="environment-variable">
<h3>3.16.4.1. Environment variable<a class="headerlink" href="#environment-variable" title="Permalink to this headline">Â¶</a></h3>
<p>A module name can be provided in the environment variable,
<code class="docutils literal notranslate"><span class="pre">NUMBA_CUDA_MEMORY_MANAGER</span></code>. If this environment variable is set, Numba will
attempt to import the module, and and use its <code class="docutils literal notranslate"><span class="pre">_numba_memory_manager</span></code> global
variable as the memory manager class. This is primarily useful for running the
Numba test suite with an EMM Plugin, e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ NUMBA_CUDA_MEMORY_MANAGER=rmm python -m numba.runtests numba.cuda.tests
</pre></div>
</div>
</div>
<div class="section" id="function">
<h3>3.16.4.2. Function<a class="headerlink" href="#function" title="Permalink to this headline">Â¶</a></h3>
<p>The <a class="reference internal" href="#numba.cuda.set_memory_manager" title="numba.cuda.set_memory_manager"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_memory_manager()</span></code></a> function can be used to set the
memory manager at runtime. This must be called prior to the initialization of
any contexts, and EMM Plugin instances are instantiated along with contexts.</p>
<p>It is recommended that the memory manager is set once prior to using any CUDA
functionality, and left unchanged for the remainder of execution.</p>
<dl class="function">
<dt id="numba.cuda.set_memory_manager">
<code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">set_memory_manager</code><span class="sig-paren">(</span><em class="sig-param">mm_plugin</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.set_memory_manager" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Configure Numba to use an External Memory Management (EMM) Plugin. If
the EMM Plugin version does not match one supported by this version of
Numba, a RuntimeError will be raised.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mm_plugin</strong> (<a class="reference internal" href="#numba.cuda.BaseCUDAMemoryManager" title="numba.cuda.BaseCUDAMemoryManager"><em>BaseCUDAMemoryManager</em></a>) â The class implementing the EMM Plugin.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="faq.html" class="btn btn-neutral float-right" title="3.17. CUDA Frequently Asked Questions" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="cuda_array_interface.html" class="btn btn-neutral float-left" title="3.15. CUDA Array Interface (Version 2)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2012-2020, Anaconda, Inc. and others

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>